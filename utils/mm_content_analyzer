const express = require('express');
const multer = require('multer');
const fs = require('fs');
const path = require('path');
const ffmpeg = require('fluent-ffmpeg');
const { OpenAI } = require('openai');
const axios = require('axios');
const FormData = require('form-data');

const app = express();
const upload = multer({ dest: 'uploads/' });

// Initialize OpenAI (for transcription and summarization)
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Initialize Google Vision API (alternative for object detection)
const vision = require('@google-cloud/vision');
const visionClient = new vision.ImageAnnotatorClient({
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS
});

class MultimediaAnalyzer {
  
  // Object Detection using Google Vision API
  async detectObjects(imagePath) {
    try {
      const [result] = await visionClient.objectLocalization(imagePath);
      const objects = result.localizedObjectAnnotations;
      
      return objects.map(object => ({
        name: object.name,
        confidence: object.score,
        boundingBox: object.boundingPoly.normalizedVertices
      }));
    } catch (error) {
      console.error('Object detection error:', error);
      throw error;
    }
  }

  // Alternative: Using Roboflow API for custom object detection
  async detectObjectsRoboflow(imagePath, modelId) {
    try {
      const form = new FormData();
      form.append('file', fs.createReadStream(imagePath));
      
      const response = await axios.post(
        `https://detect.roboflow.com/${modelId}`,
        form,
        {
          headers: {
            ...form.getHeaders(),
            'Authorization': `Bearer ${process.env.ROBOFLOW_API_KEY}`
          }
        }
      );
      
      return response.data.predictions;
    } catch (error) {
      console.error('Roboflow detection error:', error);
      throw error;
    }
  }

  // Audio/Video Transcription using OpenAI Whisper
  async transcribeAudio(audioPath) {
    try {
      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream(audioPath),
        model: "whisper-1",
        response_format: "json",
        timestamp_granularities: ["word"]
      });
      
      return {
        text: transcription.text,
        words: transcription.words
      };
    } catch (error) {
      console.error('Transcription error:', error);
      throw error;
    }
  }

  // Extract audio from video
  async extractAudioFromVideo(videoPath) {
    return new Promise((resolve, reject) => {
      const outputPath = videoPath.replace(path.extname(videoPath), '.wav');
      
      ffmpeg(videoPath)
        .toFormat('wav')
        .on('end', () => resolve(outputPath))
        .on('error', reject)
        .save(outputPath);
    });
  }

  // Text Summarization using OpenAI
  async summarizeText(text, maxLength = 150) {
    try {
      const response = await openai.chat.completions.create({
        model: "gpt-4",
        messages: [
          {
            role: "system",
            content: "You are a helpful assistant that creates concise summaries."
          },
          {
            role: "user",
            content: `Please summarize the following text in about ${maxLength} words:\n\n${text}`
          }
        ],
        max_tokens: maxLength * 2
      });
      
      return response.choices[0].message.content;
    } catch (error) {
      console.error('Summarization error:', error);
      throw error;
    }
  }

  // Comprehensive analysis combining all features
  async analyzeMultimedia(filePath, fileType) {
    const results = {
      fileType,
      timestamp: new Date().toISOString()
    };

    try {
      if (fileType.startsWith('image/')) {
        // Image analysis
        results.objects = await this.detectObjects(filePath);
        
      } else if (fileType.startsWith('audio/')) {
        // Audio analysis
        const transcription = await this.transcribeAudio(filePath);
        results.transcription = transcription;
        results.summary = await this.summarizeText(transcription.text);
        
      } else if (fileType.startsWith('video/')) {
        // Video analysis
        const audioPath = await this.extractAudioFromVideo(filePath);
        
        // Extract frame for object detection
        const framePath = await this.extractVideoFrame(filePath);
        
        results.objects = await this.detectObjects(framePath);
        const transcription = await this.transcribeAudio(audioPath);
        results.transcription = transcription;
        results.summary = await this.summarizeText(transcription.text);
        
        // Cleanup temporary files
        fs.unlinkSync(audioPath);
        fs.unlinkSync(framePath);
      }
      
      return results;
    } catch (error) {
      console.error('Analysis error:', error);
      throw error;
    }
  }

  // Extract a frame from video for object detection
  async extractVideoFrame(videoPath, timeStamp = '00:00:01') {
    return new Promise((resolve, reject) => {
      const outputPath = videoPath.replace(path.extname(videoPath), '_frame.jpg');
      
      ffmpeg(videoPath)
        .seekInput(timeStamp)
        .frames(1)
        .output(outputPath)
        .on('end', () => resolve(outputPath))
        .on('error', reject)
        .run();
    });
  }
}

const analyzer = new MultimediaAnalyzer();

// API Routes
app.post('/analyze/upload', upload.single('media'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    const filePath = req.file.path;
    const fileType = req.file.mimetype;
    
    const analysis = await analyzer.analyzeMultimedia(filePath, fileType);
    
    // Cleanup uploaded file
    fs.unlinkSync(filePath);
    
    res.json({
      success: true,
      analysis
    });
    
  } catch (error) {
    console.error('Upload analysis error:', error);
    res.status(500).json({ 
      error: 'Analysis failed', 
      message: error.message 
    });
  }
});

// Separate endpoints for specific analysis types
app.post('/analyze/objects', upload.single('image'), async (req, res) => {
  try {
    const objects = await analyzer.detectObjects(req.file.path);
    fs.unlinkSync(req.file.path);
    
    res.json({ objects });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.post('/analyze/transcribe', upload.single('audio'), async (req, res) => {
  try {
    const transcription = await analyzer.transcribeAudio(req.file.path);
    fs.unlinkSync(req.file.path);
    
    res.json({ transcription });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.post('/analyze/summarize', express.json(), async (req, res) => {
  try {
    const { text, maxLength } = req.body;
    const summary = await analyzer.summarizeText(text, maxLength);
    
    res.json({ summary });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({ status: 'OK', timestamp: new Date().toISOString() });
});

const PORT = process.env.ANALYZER_PORT || 3001;
console.log(`Note: Main DaySave app should run on port ${process.env.APP_PORT || process.env.PORT || 3000}`);
app.listen(PORT, () => {
  console.log(`Multimedia analysis server running on port ${PORT}`);
});

module.exports = app;